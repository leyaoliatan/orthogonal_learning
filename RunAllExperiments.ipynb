{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227d1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963b93b",
   "metadata": {},
   "source": [
    "# Testing: Run a single experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b4e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leahtan/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "     import sys\n",
    "     print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76da5c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from experiments import get_data_generator, exp, oracle_gen, dml, dml_split, dr, dr_split, myslearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0711485",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_fn, base_fn, tau_fn, prop_fn = get_data_generator('A', 1000, 6, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5a0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = [('dml_split', dml_split), ('slearner', myslearner)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f07ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gen_data_fn()\n",
    "results = exp(data, method_list, tau_fn, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c4781a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dml_split': 0.01726574846344717, 'slearner': 0.02008498088283078}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683453a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLWrap(model=<flaml.automl.model.LGBMEstimator object at 0x7fd3c8103940>)\n",
      "AutoMLWrap(model=<flaml.automl.model.LGBMEstimator object at 0x7fd3c81a32e0>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Cannot use a classifier as a first stage model when the target is continuous!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/experiments.py:92\u001b[0m, in \u001b[0;36mexp\u001b[0;34m(data, method_list, tau_fn, n_x)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexp\u001b[39m(data, method_list, tau_fn, n_x):\n\u001b[0;32m---> 92\u001b[0m     y, T, X, Xtest \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     93\u001b[0m     results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, method \u001b[38;5;129;01min\u001b[39;00m method_list:\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/cate.py:67\u001b[0m, in \u001b[0;36mdml\u001b[0;34m(y, T, X, Xtest, n_x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_t)\n\u001b[1;32m     61\u001b[0m est \u001b[38;5;241m=\u001b[39m NonParamDML(model_y\u001b[38;5;241m=\u001b[39mmodel_y,\n\u001b[1;32m     62\u001b[0m                   model_t\u001b[38;5;241m=\u001b[39mmodel_t,\n\u001b[1;32m     63\u001b[0m                   model_final\u001b[38;5;241m=\u001b[39mfinal_stage(),\n\u001b[1;32m     64\u001b[0m                   discrete_treatment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m                   cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     66\u001b[0m                   random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_x\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_x\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m est\u001b[38;5;241m.\u001b[39meffect(Xtest[:, :n_x]), est\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/dml/dml.py:1567\u001b[0m, in \u001b[0;36mNonParamDML.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1529\u001b[0m         cache_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;124;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/dml/_rlearner.py:415\u001b[0m, in \u001b[0;36m_RLearner.fit\u001b[0;34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mEstimate the counterfactual model from data, i.e. estimates function :math:`\\\\theta(\\\\cdot)`.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03mself: _RLearner instance\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Replacing fit from _OrthoLearner, to enforce Z=None and improve the docstring\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m                   \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/_cate_estimator.py:131\u001b[0m, in \u001b[0;36mBaseCateEstimator._wrap_fit.<locals>.call\u001b[0;34m(self, Y, T, inference, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     inference\u001b[38;5;241m.\u001b[39mprefit(\u001b[38;5;28mself\u001b[39m, Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# call the wrapped fit method\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postfit(Y, T, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# NOTE: we call inference fit *after* calling the main fit method\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/_ortho_learner.py:822\u001b[0m, in \u001b[0;36m_OrthoLearner.fit\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, freq_weight, sample_var, groups, cache_values, inference, only_final, check_input)\u001b[0m\n\u001b[1;32m    820\u001b[0m     nuisances, fitted_models, new_inds, scores \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnuisances_ref[idx])\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m     nuisances, fitted_models, new_inds, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_nuisances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_nuisances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m all_nuisances\u001b[38;5;241m.\u001b[39mappend(nuisances)\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models_nuisance\u001b[38;5;241m.\u001b[39mappend(fitted_models)\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/_ortho_learner.py:972\u001b[0m, in \u001b[0;36m_OrthoLearner._fit_nuisances\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, groups)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    970\u001b[0m         folds \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit(to_split, strata)\n\u001b[0;32m--> 972\u001b[0m nuisances, fitted_models, fitted_inds, scores \u001b[38;5;241m=\u001b[39m \u001b[43m_crossfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ortho_learner_model_nuisance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_ray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mray_remote_func_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nuisances, fitted_models, fitted_inds, scores\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/_ortho_learner.py:280\u001b[0m, in \u001b[0;36m_crossfit\u001b[0;34m(models, folds, use_ray, ray_remote_fun_option, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     nuisance_temp, model_out, score_temp \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(fold_refs[idx])\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     nuisance_temp, model_out, score_temp \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mcalculate_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulated_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    284\u001b[0m     nuisances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([np\u001b[38;5;241m.\u001b[39mfull((n,) \u001b[38;5;241m+\u001b[39m nuis\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m    285\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m nuis \u001b[38;5;129;01min\u001b[39;00m nuisance_temp])\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/_ortho_learner.py:100\u001b[0m, in \u001b[0;36m_fit_fold\u001b[0;34m(model, train_idxs, test_idxs, calculate_scores, args, kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m kwargs_test \u001b[38;5;241m=\u001b[39m {key: var[test_idxs] \u001b[38;5;28;01mfor\u001b[39;00m key, var \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     99\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_train)\n\u001b[0;32m--> 100\u001b[0m nuisance_temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nuisance_temp, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    103\u001b[0m     nuisance_temp \u001b[38;5;241m=\u001b[39m (nuisance_temp,)\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/dml/_rlearner.py:66\u001b[0m, in \u001b[0;36m_ModelNuisance.predict\u001b[0;34m(self, Y, T, X, W, Z, sample_weight, groups)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 66\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     T_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_t\u001b[38;5;241m.\u001b[39mpredict(X, W)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (W \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# In this case predict above returns a single row\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/sklearn_extensions/model_selection.py:326\u001b[0m, in \u001b[0;36mSingleModelSelector.predict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/2024-W/CPSC532Y/orthogonal_learning_codes/.venv/lib/python3.8/site-packages/econml/dml/dml.py:62\u001b[0m, in \u001b[0;36m_FirstStageWrapper.predict\u001b[0;34m(self, X, W)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use a classifier as a first stage model when the target is continuous!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mpredict(_combine(X, W, n_samples))\n",
      "\u001b[0;31mAttributeError\u001b[0m: Cannot use a classifier as a first stage model when the target is continuous!"
     ]
    }
   ],
   "source": [
    "exp(data, [('dml', dml)], tau_fn, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba031b",
   "metadata": {},
   "source": [
    "# Run all paper experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af08e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from experiments import main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ee1b8",
   "metadata": {},
   "source": [
    "### All CATE Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [500, 1000, 3000]\n",
    "d_list = [6, 12]\n",
    "sigma_list = [.5, 1, 2]\n",
    "setup_list = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "nx_list = [4, 4, 4, 5, 4, 4]\n",
    "all_res = {}\n",
    "for setup, n_x in zip(setup_list, nx_list):\n",
    "    for n in n_list:\n",
    "        for d in d_list:\n",
    "            for sigma in sigma_list:\n",
    "                target_dir = f'ortho_{setup}_{n}_{d}_{sigma}'\n",
    "                print(target_dir)\n",
    "                main(setup, n, d, n_x, sigma, 0, 2, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1551d73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_res = {}\n",
    "for setup in setup_list:\n",
    "    all_res[setup] = {}\n",
    "    for n in n_list:\n",
    "        all_res[setup][f'$n={n}$'] = {}\n",
    "        for d in d_list:\n",
    "            all_res[setup][f'$n={n}$'][f'$d={d}$'] = {}\n",
    "            for sigma in sigma_list:\n",
    "                all_res[setup][f'$n={n}$'][f'$d={d}$'][f'$\\sigma={sigma}$'] = {}\n",
    "                target_dir = f'ortho_{setup}_{n}_{d}_{sigma}'\n",
    "                filename = os.path.join(target_dir, 'res.jbl')\n",
    "                res = joblib.load(filename)\n",
    "                results = {}\n",
    "                for name in res[0].keys():\n",
    "                    all_r = [r[name] for r in res]\n",
    "                    results[f'{name}'] = f'{np.mean(all_r):.3f} ({np.std(all_r) / np.sqrt(len(all_r)):.3f})'\n",
    "\n",
    "                all_res[setup][f'$n={n}$'][f'$d={d}$'][f'$\\sigma={sigma}$'] = results\n",
    "            all_res[setup][f'$n={n}$'][f'$d={d}$'] = pd.DataFrame(all_res[setup][f'$n={n}$'][f'$d={d}$']).T\n",
    "        all_res[setup][f'$n={n}$'] = pd.concat(all_res[setup][f'$n={n}$'])\n",
    "    all_res[setup] = pd.concat(all_res[setup])\n",
    "    print(f'setup={setup}')\n",
    "    display(all_res[setup])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df147bc",
   "metadata": {},
   "source": [
    "### All Policy Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b913d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [500, 1000, 3000]\n",
    "d_list = [6, 12]\n",
    "sigma_list = [.5, 1, 2]\n",
    "\n",
    "setup_list = ['A', 'B', 'D', 'E', 'F']\n",
    "all_res = {}\n",
    "for setup in setup_list:\n",
    "    for n in n_list:\n",
    "        for d in d_list:\n",
    "            for sigma in sigma_list:\n",
    "                target_dir = f'ortho_{setup}_{n}_{d}_{sigma}'\n",
    "                print(target_dir)\n",
    "                main(setup, n, d, d, sigma, 0, 2, target_dir, policy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbfec5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_res = {}\n",
    "for setup in setup_list:\n",
    "    all_res[setup] = {}\n",
    "    for n in n_list:\n",
    "        all_res[setup][f'$n={n}$'] = {}\n",
    "        for d in d_list:\n",
    "            all_res[setup][f'$n={n}$'][f'$d={d}$'] = {}\n",
    "            for sigma in sigma_list:\n",
    "                all_res[setup][f'$n={n}$'][f'$d={d}$'][f'$\\sigma={sigma}$'] = {}\n",
    "                target_dir = f'ortho_{setup}_{n}_{d}_{sigma}'\n",
    "                filename = os.path.join(target_dir, 'res_policy.jbl')\n",
    "                res = joblib.load(filename)\n",
    "                results = {}\n",
    "                for name in res[0].keys():\n",
    "                    all_r = [r[name] for r in res]\n",
    "                    results[f'{name}'] = f'{np.mean(all_r):.3f} ({np.std(all_r) / np.sqrt(len(all_r)):.3f})'\n",
    "\n",
    "                all_res[setup][f'$n={n}$'][f'$d={d}$'][f'$\\sigma={sigma}$'] = results\n",
    "            all_res[setup][f'$n={n}$'][f'$d={d}$'] = pd.DataFrame(all_res[setup][f'$n={n}$'][f'$d={d}$']).T\n",
    "        all_res[setup][f'$n={n}$'] = pd.concat(all_res[setup][f'$n={n}$'])\n",
    "    all_res[setup] = pd.concat(all_res[setup])\n",
    "    print(f'setup={setup}')\n",
    "    display(all_res[setup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc8df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
